{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e28a3f9c-8889-43ad-96f3-abb390fa194e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcb8c86f-2875-449f-a248-3a4cc4f268a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import Row, SparkSession, types as T # pyspark==4.0.0\n",
    "from pyspark.sql.datasource import DataSource, DataSourceReader # pyarrow required, used: pyarrow==19.0.1\n",
    "import requests # used: requests==2.32.4\n",
    "# optional, for jupyter notebook: ipykernel==6.26.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "308b1c68-7899-4151-9e57-da2c3582327a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Utils:**\n",
    "[StackOverflow rules!!!](https://stackoverflow.com/questions/74105403/determine-if-code-is-running-on-databricks-or-ide-pycharm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c4ffd16-b16d-4650-85de-927f2a3582e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "is_databricks_session = \"DATABRICKS_RUNTIME_VERSION\" in os.environ\n",
    "\n",
    "def show_dataframe(df, is_databricks):\n",
    "    if is_databricks:\n",
    "        display(df)\n",
    "    else:\n",
    "        df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ca23e0f-e908-4e45-b9b2-a89cf1b1c2e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **SparkSession**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "128fea9b-e622-4537-90c3-6d9fc2d1861b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if not is_databricks_session:\n",
    "    spark = (\n",
    "        SparkSession.builder\n",
    "            .master(\"local[3]\")\n",
    "                .appName(\"pyspark_custom_datasource\")\n",
    "                    .getOrCreate()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b6f00d5-e573-42c4-980c-b6a19a81b071",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **ChuckNorrisDataSource statement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e31238a3-1eb6-48d8-92a7-f83db196bba0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class ChuckNorrisDataSource(DataSource):\n",
    "    \"\"\"\n",
    "    A DataSource for reading facts (jokes) from the Chuck Norris API.\n",
    "\n",
    "    Name: `chucknorris`\n",
    "\n",
    "    Schema: `id string, fact string, category string`\n",
    "\n",
    "    Options:\n",
    "        count: int \n",
    "            The number of facts to be returned. Default is 1\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    Register the data source:\n",
    "\n",
    "    >>> from your_module import ChuckNorrisDataSource\n",
    "    >>> spark.dataSource.register(ChuckNorrisDataSource)\n",
    "\n",
    "    Load a few facts (you can specify how many):\n",
    "\n",
    "\n",
    "    >>> spark.read.format(\"chucknorris\").option(\"count\", 5).load().show()\n",
    "    +--------------------+--------------------+-----------+\n",
    "    |                 id |                fact|   category|\n",
    "    +--------------------+--------------------+-----------+\n",
    "    | ykC28btrRCm4Vqev...| Chuck Norris can...|     animal|\n",
    "    |        ...         |               ...  |       ... |\n",
    "    +--------------------+--------------------+-----------+\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def name(cls):\n",
    "        return \"chucknorris\"\n",
    "\n",
    "    def schema(self):\n",
    "        return T.StructType([\n",
    "            T.StructField(name=\"id\", dataType=T.StringType(), nullable=False),\n",
    "            T.StructField(name=\"fact\", dataType=T.StringType(), nullable=False),\n",
    "            T.StructField(name=\"category\", dataType=T.StringType(), nullable=False)\n",
    "        ])\n",
    "\n",
    "    def reader(self, schema):\n",
    "        return ChuckNorrisReader(self.options)\n",
    "\n",
    "\n",
    "class ChuckNorrisReader(DataSourceReader):\n",
    "    def __init__(self, options):\n",
    "        self.count = int(options.get(\"count\", 1))  # Default: 1 fact\n",
    "\n",
    "    def read(self, partition):\n",
    "        url = \"https://api.chucknorris.io/jokes/random\"\n",
    "        for _ in range(self.count):\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            fact_data = response.json()\n",
    "            yield Row(\n",
    "                id=fact_data.get(\"id\"),\n",
    "                fact=fact_data.get(\"value\"),\n",
    "                category=(\n",
    "                    fact_data.get(\"categories\")[0]\n",
    "                    if fact_data.get(\"categories\")\n",
    "                    else \"uncategorized\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "spark.dataSource.register(ChuckNorrisDataSource)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b7e1d05-4f78-47b2-98e8-3d07a681d138",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Reading ChuckNorrisDataSource**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8cbe9da-4998-41ad-a793-e26f3e8ab3c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Getting 5 random facts\n",
    "show_dataframe(\n",
    "    df=spark.read.format(\"chucknorris\")\n",
    "        .option(\"count\", 5)\n",
    "            .load(),\n",
    "    is_databricks=is_databricks_session\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7329149f-6b6a-44ca-a5ce-b11566aca10b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "show_dataframe(\n",
    "    df=spark.read.format(\"chucknorris\")\n",
    "        .load(),\n",
    "    is_databricks=is_databricks_session\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "custom_sources",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
